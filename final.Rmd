---
s   ---
title: "final_sna"
author: "Phong Duong, Nienke Visscher, Frederick Sims"
date: "2024-05-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

# Libraries

```{r}
library(tidyverse)
library(igraph)
library(patchwork)
library(randomForest)
library(caret)
```

# Import Data

The data set used in this report is obtained from (LINK). The data file is in .csv format and contains 160,781 rows and 11 columns including information about the country of origin of the migration (name and country code), the country of destination (name and country code), and the information about the migration (gender, gender code, the amount of immigrants from 1960 to 2000 in decennial intervals).

```{r}
data <- read_csv("migration_data.csv") %>% 
  rename(source = "Country Origin Name",
         target = "Country Dest Name",
         migration_2000 = "2000 [2000]") %>% 
  select(source, target, migration_2000) %>% 
  mutate(
    source = gsub(x = source, pattern = "\\.", replacement = ""),
    target = gsub(x = target, pattern = "\\.", replacement = ""),
    migration_2000 = as.numeric(migration_2000)) %>% 
  filter(migration_2000 > 0) %>% 
  group_by(source,target) %>% 
  summarise(migration_2000 = sum(migration_2000))
data %>% head()
```

First, we loaded the data into a variable, selecting only the name of country of origin ("source"), name of country of destination("target"), and the amount of immigrants of the migration in the year 2000 ("migration_2000"). We also removed the period (".") in the names of the countries both of origin and destination as later on we will perform a separation method which is affected if the name of the country contains the period. Next we converted the "migration_2000" into the proper data type (character to numeric) and filtered out the empty migrations. Since there are multiple migrations in the same year for the same pairs of countries, we summarized them so they are counted as one link instead of multiple links for the same pair. After this, we are left with a data frame of 23,718 observations.

```{r}
g <- graph_from_data_frame(data, directed = TRUE) %>% 
  simplify(.) 
E(g)$weight <- data$migration_2000
g
```

Next, we built the network graph with the function `graph_from_data_frame()`. We also removed any loops and multiple edges with the function `simplify()` and it seems that there are no extra edges as the number of edges stay the same. We then added the weight attribute to the edges using the amount of immigrants as weight. From the information of the graph, we can see that there are 226 vertices (or countries) and 23,718 edges (or migrations among those countries).

```{r}
par(mar=c(0,0,0,0))
plot(g, directed = TRUE, weighted = TRUE,
     edge.arrow.size = 0.2,
     edge.color = adjustcolor("grey30", 0.2),
     vertex.color = ifelse(degree(g) > 10, "orange", "grey50"),
     vertex.size = 4,
     vertex.label = "")
```

We also visualized the network to have a brief ideas of how it looks like. (To be redacted by mapping the countries to its geographical locations).

# Propagation Simulation

We want to simulate the propagation of information on this network using the SIR model assuming that an infected person can transmit the information with probability β to a susceptible person on the network.

For our network, we can think of this as information spreading between countries through immigration. That is a susceptible country would be one in which the information had not yet reached anyone in the country. An infected country would then be one that has already gotten hold of the information and now has a probability of spreading the information through the migrations. Finally, a recovered country would be one that is no longer able to spread the information. An analogy to this could be that the information is no longer trending in the country and therefore ceased to spread.

## Epidemic Threshold

a)  Find the theoretical epidemic threshold β for your network for the information to reach a significant number of nodes.

```{r}
mu <- 0.1
betac <- mu*mean(degree(g))/(mean(degree(g)^2))
betac
```

To find the theoretical epidemic threshold β, we first defined a recovery rate mu of 0.1. This means that between each step (a defined period of time), each infected country has a 0.1 probability of stopping the spread of information and becoming immune to the spreading from the infected countries.

We then calculated the epidemic threshold using the formula:

$$ \beta_c = \mu \frac{\langle k \rangle}{\langle k^2 \rangle}$$

We obtained a β of 0.0004, which is very low. This means that if the infection rate (or information propagation rate) is higher than 0.0004, an epidemic will occur at some time *t.* Since our network only has 226 nodes but there are a lot of edges, the possibility of a epidemic is high as there are many contacts between the nodes and the network is not at all large so it is not at all surprising that information can easily spread through out all of the network.

## Simulation

b)  Assuming that randomly-selected 1% of the nodes of your network knows about the information, simulate the SIR model below and above that threshold and plot the number of infected people as a function of β.

First we will build a function to simulate this model. Since our network consists of countries and the amount of immigrants moving between them, we can consider the amount of immigrants when simulating an infection too add more complexity to the model. The model will now have a weighted probability β~ij~ for susceptible country *j* calculated by multiplying the base infection rate β with the normalized log of the amount of immigrants from country *i* to country *j* divided by the total log of the amount of immigrants country *j* receives. The formula for β~ij~ is henceforth:

$$ \beta_{ij} = \beta \frac{\log{w_{ij}}}{\sum_i \log{w_{ij}}}$$

In which β is the base infection rate (or information propagation rate) and w~ij~ is the amount of immigrants from country *i* to country *j*. The model therefore gives higher probability of being infected (capping at β) to countries with higher amount of incoming immigrants in comparison to countries with low immigrants.

```{r}
sim_sir <- function(g,beta,mu,seeds){
  state <- rep(0,vcount(g)) #initial state of the simulation
  state[seeds] <- 1 #infect the seeds
  t <- 0
  table <- data.frame(t=0,inf=seeds)
  while(sum(state==1)>0){
    t <- t + 1
    ## I -> R
    infected <- which(state==1) #get them
    
    # generate a random value for every infected, if it's < mu, let the node recover.
    state[infected] <- ifelse(runif(length(infected)) < mu,2,1)
    
    ## S -> I
    infected <- which(state==1)
    susceptible <- which(state==0) #get them
    
    ###Get contacts with weighted edges
    if(sum(state ==0) >0 & sum(state == 1) > 0) { #stop generating infection once all are recovered
    contacts <- adjacent_vertices(g, infected) %>% #find neighbors of infected vertices
      unlist() %>% 
      names() %>% #get the names of all the nodes
      sub(patter = "\\.", replacement =  "%") %>% 
      data.frame() %>% 
      separate(".", c("vi", "vj"), sep = "%") %>% #separate source and target nodes in pairs to id 
      mutate(vi_id = lapply(vi, function(x){id <- which(V(g)$name == x)}) %>% unlist(), #id source node
             vj_id = lapply(vj, function(x){id <- which(V(g)$name == x)}) %>% unlist(), #id target node
             weight = E(g)[vi_id %->% vj_id]$weight) %>% #add weight of the link
      filter(vj_id %in% susceptible) %>% #filter only susceptible nodes 
      #calculate beta_ij weighted by immigrant amount
      group_by(vj_id) %>% 
      mutate(sum_i_log_wij = sum(log(weight))) %>% 
      ungroup() %>%
      mutate(beta_ij = ifelse(sum_i_log_wij == 0, 0 ,beta * log(weight) / sum_i_log_wij))
    
    ###Generate infection
    new_infected <- lapply(contacts$beta_ij, function(x){inf <- runif(1) < x}) %>% unlist()
    new_infected <- contacts$vj_id[new_infected]
    new_infected <- new_infected[!duplicated(new_infected)]
    
    ### Append nodes newly infected into the table
    if(length(new_infected)>0){
      state[new_infected] <- 1
      table <- rbind(table,data.frame(t,inf=new_infected))
    }
    }
  }
  table
}
```

The simulation function consists of 3 main components: the initial state of the network, the recovery simulation, and the infection simulation.

First, the function initiates with all vertices at susceptible state (information has not been spread to nor able to spread information). The function then assigns the infection according to the provided seeds (selected countries). Time *t* is set at 0. Finally, a table is created to record the infected vertices during time *t*.

Next, the function runs a while loop until no node is in the infected state. For each loop, time *t* increased by 1. Then, the infected nodes are saved into a variable and sequentially given a chance to recover if the assigned random probability is lower than mu. This concludes the simulation of recovery.

Finally, the loop continues to simulate the spread of information (or infection) by first saving the infected and susceptible nodes into variables. It then runs the infection spreading if there are infected and susceptible nodes. This condition was put in place to stop generating infection over recovered nodes after all nodes have been infected or when there are no infectious nodes. The infection is realized by:

-   Finding the neighbors of the infected nodes (countries that have migrations from infected countries)

-   Identifying the id of the nodes (in this step, `adjacent_vertices()` gives names of country pairs separated by ".", for example "Congo. United States", therefore, we had to remove the "." in the country name in the data initially so we can separate them here with `separate()` function),

-   Adding the amount of immigrants (or the weight of the edge) for the pair of countries

-   Filter to keep only the destination (migrated to) country (v~j~) that are susceptible

-   Calculating β~ij~ of each destination country

-   Generating a random probability for each destination country, if the number is lower than their β~ij~ then they are infected

-   Removing duplicated countries since some countries have overlapped neighbors

These newly infected nodes are then saved into the recording table. Using this simulation function, we can now simulate the information propagation with 2 scenarios, one where the infection rate β is higher than the epidemic threshold and one where the infection rate is lower than the threshold.

### Above Threshold

```{r}
set.seed(230)
# Sample 1% of the network as initial infectious seed
seeds <- sample(1:vcount(g),0.01*vcount(g))
# Generate a simlulation of the SIR model with beta above threshold
realization_at <- sim_sir(g,beta = 0.3,mu=0.1,seeds) 
distinct(realization_at, inf)
```

We first generate a random sample of 1% of the nodes as the initial infected states. We then run the simulation setting β at 0.3, mu at 0.1, and seeding with the countries previously generated. The resulting table from the simulation has 226 distinct rows, indicating that all nodes have been infected at some time *t*. This is exactly what we expected since the infection rate β is higher than the threshold β~c~ at 0.0004. We next will build a graph to see how the information was spreading throughout the simulation.

```{r}
realization_at <- realization_at %>% 
  group_by(t) %>% summarize(ninf=n()) 
realization_at %>% 
  ggplot(aes(x=t,y=ninf)) + geom_line()
```

From the visualization, we can see that the information spread quickly at the beginning and peaked at around 43 new infected node around time *t* = 2. Since a large portion of the network has already been infected at this point, the amount of recovered country also went up. In addition to the fact that less countries are susceptible to be spread information to, the spreading starts to subside and around time *t* = 10, the majority of the nodes have already been spread the information to.

### Below threshold

```{r}
set.seed(230)
# Sample 1% of the network as initial infectious seed
seeds <- sample(1:vcount(g),0.01*vcount(g))
# Generate a simlulation of the SIR model with beta below threshold
realization_bt <- sim_sir(g,beta = 0.0002, mu=0.01,seeds) 
realization_bt
```

Similarly, we realized a simulation at β = 0.0002, lower than the threshold β~c~ = 0.0004, expecting the spread to be mellow. We can observe from the resulting table that in total, there are only 4 countries (nodes) that have been infected throughout the simulation, including the initial infected seeding nodes. At time *t* = 17, one new node was infected and finally at time *t* = 36, one new node is infected and all seem to recover after that. We can also see this in the graph below.

```{r}
realization_bt <- realization_bt %>% 
  group_by(t) %>% summarize(ninf=n()) 
realization_bt %>% 
  ggplot(aes(x=t,y=ninf)) + geom_line()
```

The graph is clearly different from the graph where infection rate β is higher than the threshold. Here, we can see that the seeding nodes were barely able to spread the infection and only minimal nodes were infected throughout the simulation.

### Different Betas

```{r}
set.seed(230)
results <- map_dfr(seq(0,0.2,0.01), # beta range
        \(beta){ seeds <- sample(1:vcount(g),vcount(g)*0.01)
        realization <- sim_sir(g,beta,mu,seeds) # make a realization for each beta
        data.frame(beta,ninf=nrow(realization)) # create dataframe row
        })
results %>% ggplot(aes(x=beta,y=ninf))+ geom_point()+
  geom_vline(xintercept = betac,linetype=2)
```

## Better 1% seeds

c)  Choose a β above β~c~. Using centrality, communities or any other metric, find a better set of 1% of seeds in the network so we get more infected people than the random case. Measure the difference of your choice with the random case.

Beside assigning the seeds at random, we will also use closeness, betweenness, and page rank to target certain nodes that are more "important" (or well connected) to see the effect of the information spread. This is simply done by calculating each metric for each node then find the 1% with the highest values and use them as seeds for the simulation. The infection rate is set at 0.3 here to ensure that an epidemic is bound to happen. We will also visualize the spreading to compare between the different methods.

```{r}
set.seed(230)
beta_at <- 0.3
#target at random
seeds_random <- sample(1:vcount(g),vcount(g)*0.01)
realization_random <- sim_sir(g,beta = beta_at,mu=0.1,seeds_random) %>%
  group_by(t) %>% summarize(ninf=n())
#target by closeness
seeds_closeness <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  slice_max(closeness,n= round(vcount(g)*0.01))
realization_closeness <- sim_sir(g,beta = beta_at,mu=0.1,which(V(g)$name %in% seeds_closeness$inf)) %>%
  group_by(t) %>% summarize(ninf=n())
#target by betweenness
seeds_between <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  slice_max(betweenness,n= round(vcount(g)*0.01))
realization_between <- sim_sir(g,beta = beta_at,mu=0.1,which(V(g)$name %in% seeds_between$inf)) %>%
  group_by(t) %>% summarize(ninf=n())
#target using page rank
seeds_pagerank <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  slice_max(page_rank,n= round(vcount(g)*0.01))
realization_pagerank <- sim_sir(g,beta = beta_at,mu=0.1,which(V(g)$name %in% seeds_pagerank$inf)) %>%
  group_by(t) %>% summarize(ninf=n())

ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Target at random"))+
  geom_line(data=realization_closeness,aes(x=t,y=ninf,col="Target by closeness")) +
  geom_line(data=realization_between,aes(x=t,y=ninf,col="Target by betweenness")) +
  geom_line(data=realization_pagerank,aes(x=t,y=ninf,col="Target by page rank"))
```

We can firstly see that targeting by closeness and by page rank make the propagation go much faster than by targeting the initial nodes at random. Overall, targeting by betweenness, closeness, or page rank all makes the information spread faster than by targeting at random. It also seems that using page rank, the spreading reaches all the nodes and concludes the simulation much faster than other methods.

-   The difference in the total number of infected people

```{r}
realization_random$ninf %>% sum()
realization_between$ninf %>%  sum()
realization_closeness$ninf %>%  sum()
realization_pagerank$ninf %>% sum()
```

All methods seem to be able to infect all of the network in the simulation. Since our network is small with only 226 nodes, this is not unusual. We can better compare the methods by looking at the time it takes for each method to peak in the infection.

-   The difference in the time of the peak of infection (when most infections happen).

```{r}
rbind(
  slice_max(realization_random, ninf),
  slice_max(realization_between, ninf),
  slice_max(realization_closeness, ninf),
  slice_max(realization_pagerank, ninf)
) %>% cbind(target_by = c("random", "between", "closeness", "page rank"))
```

It seems that although targeting by closeness makes the spreading peak with higher amount of infected nodes (at 58). However, page rank takes 1 step less to peak (at *t* =1) and the amount of new infected nodes is almost as high as the peak of closeness (53 vs. 58 respectively). Furthermore, we also saw that targeting by page rank also concluded the simulation faster. Therefore, targeting by page rank might be the most effective method to spread information through immigrants in the year 2000.

Nevertheless, it is absolutely important to acknowledge that this could have been due to chances. More simulation needs to be done using each method to generate a more accurate result.

## Information stoppers

### 5% randomly

d)  Choose those 5% randomly in the network. Simulate the SIR model above using beta\~c 1% of the remaining nodes as seeds. Choose those seeds randomly.

```{r}
beta_at <- 0.1
```

```{r}
set.seed(230)
vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)
gp_random <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp_random),vcount(gp_random)*0.01)
vaccination_random <- sim_sir(gp_random,beta = beta_at,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

### Vaccination according to their centrality

Choose those 5% according to their centrality. Simulate the SIR model above using 1% of the remaining nodes as seeds. Choose those seeds randomly.

```{r}
# immunization by closeness
set.seed(4785)
vaccinated_closeness <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  slice_max(closeness,n = round(vcount(g)*0.05))
gp_closeness <- delete_vertices(g,vaccinated_closeness$inf)
seeds <- sample(1:vcount(gp_closeness),vcount(gp_closeness)*0.01)
vaccination_targeted_closeness <- sim_sir(gp_closeness,beta = beta_at,mu=0.1, seeds) %>% 
  group_by(t) %>%
  summarize(ninf=n())

# immunization by betweenness
set.seed(4575)
vaccinated_between <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  slice_max(betweenness,n=round(vcount(g)*0.05))
gp_between <- delete_vertices(g,vaccinated_between$inf)
seeds <- sample(1:vcount(gp_between),vcount(gp_between)*0.01)
vaccination_targeted_between <- sim_sir(gp_between,beta = beta_at,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

# immunization by page rank
set.seed(365)
vaccinated_pagerank <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  slice_max(page_rank,n=round(vcount(g)*0.05))
gp_pagerank <- delete_vertices(g,vaccinated_pagerank$inf)
seeds <- sample(1:vcount(gp_pagerank),vcount(gp_pagerank)*0.01)
vaccination_targeted_pagerank <- sim_sir(gp_pagerank,beta = beta_at,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Measure the difference between both cases as you did in part c).

```{r}
ggplot() + 
  geom_line(data=vaccination_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=vaccination_targeted_closeness,aes(x=t,y=ninf,col="Vacc. Targeted Closeness"))+ 
  geom_line(data=vaccination_targeted_between,aes(x=t,y=ninf,col="Vacc. Random Between"))+
  geom_line(data=vaccination_targeted_pagerank,aes(x=t,y=ninf,col="Vacc. Targeted PageRank"))
```

-   The difference in the total number of infected people

```{r}
vaccination_random$ninf %>% sum()
vaccination_targeted_closeness$ninf %>%  sum()
vaccination_targeted_between$ninf %>% sum()
vaccination_targeted_pagerank$ninf %>%  sum()
```

-   The difference in the time of the peak of infection (when most infections happen).

```{r}
max(vaccination_random$ninf)
max(vaccination_targeted_closeness$ninf)
max(vaccination_targeted_between$ninf)
max(vaccination_targeted_pagerank$ninf)
```

## Effect of vaccination

Comment on the relationship between the findings in part c) and d) using the same type of centrality for the 1% in part c) and 5% in part d).

## Building a predictive model

With the results of part b) train a model that predicts that time to infection of a node using their degree, centrality, betweeness and page rank. Use that model to select the seed nodes as those with the smallest time to infection in part c). Repeat d).

```{r}

#RESULTS OF PART B
# Sample 1% of the network as initial infectious seed
seeds <- sample(1:vcount(g),0.01*vcount(g))
# Generate a simlulation of the SIR model with beta above threshold
realization_at <- sim_sir(g,beta = 0.3,mu=0.1,seeds) 
realization_at
```

First, we compute the degree, centrality, betweenness and pagerank for each node and combine these metrics with the output of the spreading simulation into a table. Then, this table is used to visualise the relationship between the metric and the time of infection (t)

**1) degree**

```{r,fig.height=3}

set.seed(230)
#Above treshold

V(g)$name <- as.character(1:vcount(g))

table_d_at <- degree(g) %>% enframe(name = "inf",value="degree") %>%
  merge(realization_at) 

p1 <-table_d_at %>% 
  ggplot(aes(x=t,y=degree)) + geom_point() + 
  geom_smooth(method = "lm", se = FALSE, color = "purple")+
  scale_y_log10()

```

**2) centrality**

```{r}

set.seed(230)
#Above treshold
table_c_at <- closeness(g) %>% enframe(name = "inf",value="closeness") %>%
  merge(realization_at) 

p2 <-table_c_at %>% 
  ggplot(aes(x=t,y=closeness)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "purple")+
  scale_y_log10()
```

**3) betweeness**

```{r}
set.seed(230)
#Above treshold
table_b_at <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  merge(realization_at)

p3 <-table_b_at %>% 
  ggplot(aes(x=t,y=betweenness)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, color = "purple")+
  scale_y_log10()

```

**4) page rank**

```{r}
set.seed(230)
#Above treshold
table_pr_at <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  merge(realization_at) 

p4<-table_pr_at %>% 
  ggplot(aes(x=t,y=page_rank)) + 
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "purple")+
  scale_y_log10()

```

```{r}
set.seed(230)

p1+p2+p3+p4

#Above treshold
df <- merge(table_b_at, table_c_at)
df <- merge(table, table_d_at)
df <- merge(table, table_pr_at)
cor(df$t,df[,-c(1,2)])
```

The plots and the correlation matrix show that the metrics are only weakly associated with the time of infection.

In the following section, we train a model to predict the tine of infection based on the four metrics evaluated above. First, the data is splitted into training (80% ) and testing (20% ) data sets. Th train control is set to utilising 10 fold cross validations. Then, three different machine learning algorithms are trained to predict the time to infection. The first algorithm is a *random forest* which is an ensemble learning method that constructs multiple decision trees during training and outputs the mean prediction (regression) of the individual trees as its result. The second algorithm is a *poisson regression* this model is designed to estimate models with a non-negative discrete outcome variable. The last algorithm is a *neural network* is a computational model inspired by the structure and function of the human brain, composed of interconnected nodes organized in layers, capable of learning complex patterns from data through iterative training algorithms.

```{r}
options(scipen = 999)

# Target
target <- df$t

# Split data into training and test sets
set.seed(123)  # for reproducibility
trainIndex <- createDataPartition(target, p = .8, 
                                  list = FALSE, 
                                 times = 1)

#Create a train and test data set
trainData <- df[trainIndex,]
testData <- df[-trainIndex,]

train_control <- trainControl(method = "cv", number = 10) 

#TRAINING THE MODEL
# Train a Random Forest model
# Train Random Forest model using caret
rf_model <- train(t ~ degree + closeness + betweenness + page_rank, 
                  data = trainData, 
                  method = "rf", 
                  trControl = train_control)

#Train a poison model using caret
poisson_fit <- train(t ~ degree + closeness + betweenness + page_rank, 
                         data = trainData, 
                     method = "glm", family = poisson,
                     trControl = train_control)

#Train a neural network
nn_fit <- train(t ~ degree + closeness + betweenness + page_rank, 
                         data = trainData, 
                     method = "nnet",
                     trControl = train_control)



results <- resamples(list(random_forest = rf_model, poisson =poisson_fit, neural_network = nn_fit))
summary(results)


# Predict on the test set
predictions <- predict(rf_model, testData)
testData$predictions <- predictions

#Plot predicted vs actual time to infection
ggplot(testData, aes(x = t, y = predictions)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = 'red') +
  labs(title = "Predicted vs Actual Time to Infection",
       x = "Actual Time to Infection",
       y = "Predicted Time to Infection") +
  theme_minimal()

```

The accuracy metrics do not seem to differ greatly and we select the predictions based on the random forest model. The graph visualising the predicted vs actual time to infection shows that the random forest model does not predict the time to infection precisely. As the network is rather small and the training set used to train the model is also relatively small, causing the algorithm to not have sufficient data points to learn and provide precise prediction.

### Nodes with lowest time to infection

We use the predicted time to infections to select 1% of the nodes with the lowest predicted time to infection. Then, these nodes are used as seeds to simulate spreading in the network. We compare this spreading with the spreading of a simulation with randomly selected seeds.

```{r}
set.seed(230)

# Predict the time to infection for all nodes
all_predictions <- predict(rf_model, df)

# Add predictions to the data frame
df$predicted_t <- all_predictions

#Calculate 1% of the total nodes
num_seeds <- nrow(df)*0.01 

# Select 1% of the nodes with the smallest predicted time to infection
seed_min_t <-df |> 
  slice_min(predicted_t, n=round(num_seeds))

#Randomly select 1% of the nodes in the network
seeds_random <- sample(1:vcount(g),vcount(g)*0.01)
realization_random <- sim_sir(g,beta = 0.3,mu=0.1,seeds_random) %>%
  group_by(t) %>% summarize(ninf=n())

seed_min_t$inf <- as.numeric(seed_min_t$inf)


```

### Applying seeds with lowest time to infection

```{r}

#Simulate spreading in the network with seeds being nodes with the lowest predicted time to infection
realization_targeted_rf <- sim_sir(g,beta = 0.3,mu=0.1, seed_min_t$inf) %>%
  group_by(t) %>% summarize(ninf=n())

ggplot() + 
  geom_line(data = realization_random, aes(x = t, y = ninf, color = "Random")) +
  geom_line(data = realization_targeted_rf, aes(x = t, y = ninf, color = "Targeted")) +
  scale_color_manual(name = "Seed selection", 
                     values = c("Random" = "purple", "Targeted" = "darkgreen")) +
  labs(title = "Infection Spread Over Time",
       x = "Time (t)",
       y = "Number of Infected Nodes (ninf)") +
  theme_minimal()


realization_random |> 
  left_join(realization_targeted_rf, by = c("t"="t")) |> 
  rename(ninf_random = ninf.x, ninf_target = ninf.y) |> 
  mutate(diff_target_random = ninf_target-ninf_random) |> 
  ggplot()+
  geom_line(aes(x = t, y =  diff_target_random), color = "purple")+
  geom_line(data = realization_random, aes(x = t, y = ninf, color = "Random")) +
  geom_line(data = realization_targeted_rf, aes(x = t, y = ninf, color = "Targeted")) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red")+
  scale_color_manual(name = "Seed selection", values = c("Random" = "darkgrey", "Targeted" = "lightgrey")) +
  labs(title = "Difference infection spread targeted seed vs random seed",
       x = "Time (t)",
       y = "Difference number of infection targeted seed vs random seed") +
  theme_minimal()
  
paste("The total number of infections in the random SIR model are ", realization_random$ninf %>% sum(), "infections" )

paste("The total number of infections in the targeted SIR model are ", realization_targeted_rf$ninf %>%  sum(), "infections" )

paste("The difference in number of infections between the targeted and the random SIR model is", (realization_targeted_rf$ninf %>%  sum()) - (realization_random$ninf %>% sum()), "infections" )

paste("The maximum number of infections at one timepoint in the random SIR model is",max(realization_random$ninf), "infections")

paste("The maximum number of infections at one timepoint in the targeted SIR model is",max(realization_targeted_rf$ninf), "infections")

paste("The difference in number of maximum infections between the targeted and the random SIR model is", (max(realization_targeted_rf$ninf)) - (max(realization_random$ninf)), "infections" )



```

The graphs show a highly similar course of infections. However, the targeted simulation shows a higher peak of infections earlier in the simulation compared to the random simulation. Also, the targeted simulation has higher maximum number of infections at a one time point then the random simulation. However, in both simulation the entire network ends up infected.

### Vaccination according to time to infection

To start, we randomly selected 5% of the nodes and stored these nodes in the variable *vaccinated_random.* Then we created an igraph prime object, *gp_random,* in which the vertices attached to the 5% of the randomly selected nodes are deleted. In other words, 5% of the nodes in the network is vaccinated. From this reduced igraph object, *gp_random,* we randomly selected 1% of the nodes as seeds and simulated the sir model with 1% random seeds and 5% randomly vaccinated nodes. Then we repeated this process, however this time selecting the 5% of nodes to be vaccinated based on the lowest time to infection. Finally, we compared these two models.

```{r}
beta_at <- 0.1
```

```{r}
set.seed(230)

#Randomely select 5% of the nodes
vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)

#Create an igraph prime object in which the vertices attached to the 5% of the randomly selected nodes are deleted 
gp_random <- delete_vertices(g,vaccinated_random)

#From this reduced igraph object randomly selects 1% of the nodes as seeds
seeds <- sample(1:vcount(gp_random),vcount(gp_random)*0.01)

#Simulate the sir model with 1% random seeds and 5% nodes randomely vaccinated
vaccination_random <- sim_sir(gp_random,beta = beta_at,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

```{r}
set.seed(4785)

#Calulate 5% of the nodes 
num_seeds <- nrow(df)*0.05  # Selecting 5% of the nodes

# Select nodes with the smallest predicted time to infection
seed_min_t <-df |> 
  slice_min(predicted_t, n=round(num_seeds))

#Seed IDs as numeric 
seed_min_t$inf <- as.numeric(seed_min_t$inf)

##Create an igraph prime object in which the vertices attached to the 5% of the nodes with the smallest time to infection are deleted
gp_rf<- delete_vertices(g, seed_min_t$inf)
gp_rf

#From this reduced igraph object randomly selects 1% of the nodes as seeds
seeds <- sample(1:vcount(gp_rf),vcount(gp_rf)*0.01)

#Simulate the sir model with 1% random seeds and 5% nodes vaccinated based on their lowest time to infection
vaccination_targeted_rf <- sim_sir(gp_rf ,beta = beta_at,mu=0.1, seeds) %>% 
  group_by(t) %>%
  summarize(ninf=n())

#Plot the SIR models
ggplot() + 
  geom_line(data=vaccination_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=vaccination_targeted_rf,aes(x=t,y=ninf,col="Vacc. Targeted"))+
  scale_color_manual(name = "Seed selection", values = c("Vacc. Random" = "purple", "Vacc. Targeted" = "red"))+
  labs(title = "Infection spead random vaccinated vs targeted vaccinated SIR model",
       x = "Time (t)",
       y = "Number of infections") +
  theme_minimal()

#Plot the random and targeted vaccinated SIR models and plot the difference in infections between these two
vaccination_random |> 
  left_join(vaccination_targeted_rf, by = c("t"="t")) |> 
  rename(ninf_random = ninf.x, ninf_target = ninf.y) |> 
  mutate(diff_target_random = ninf_target-ninf_random) |> 
  ggplot()+
  geom_line(aes(x = t, y =  diff_target_random), color = "purple")+
  geom_line(data = vaccination_random, aes(x = t, y = ninf, color = "Random")) +
  geom_line(data = vaccination_targeted_rf, aes(x = t, y = ninf, color = "Targeted")) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red")+
  scale_color_manual(name = "Seed selection", values = c("Random" = "darkgrey", "Targeted" = "lightgrey")) +
  labs(title = "Difference infection spead random vaccinated vs targeted vaccinated SIR model",
       x = "Time (t)",
       y = "Difference targeted vaccinated vs randomly vaccinated SIR model") +
  theme_minimal()
  
paste("The total number of infections in the randomly vaccinated SIR model are ", vaccination_random$ninf %>% sum(), "infections" )

paste("The total number of infections in the targeted vaccinated SIR model are ", vaccination_targeted_rf$ninf %>%  sum(), "infections" )

paste("The difference in number of infections between the targeted and the randomly vaccinated SIR model is", (vaccination_targeted_rf$ninf %>%  sum())- (vaccination_random$ninf %>% sum()), "infections" )

paste("The maximum number of infections at one timepoint in the randomly vaccinated SIR model is",max(vaccination_random$ninf), "infections")

paste("The maximum number of infections at one timepoint in the targeted vaccinated SIR model is",max(vaccination_targeted_rf$ninf), "infections")

paste("The difference in number of maximum infections between the targeted and the randomly vaccinated SIR model is", (max(vaccination_targeted_rf$ninf)) - (max(vaccination_random$ninf)), "infections" )
```

As one can see in the visualisations, the course of infections when a part of the network is vaccinated differs from the non-vaccinated SIR models as these models take about double the time until the number of new infections has reached 0. Interestingly, the targeted vaccinated SIR model shows higher peaks of infections in the earlier stages of the model than the randomly vaccinated SIR model. Also the randomly vaccinated SIR model has one more infected node at the end of the simulation compared to the targeted vaccinated SIR model. The targeted vaccinated SIR model has 3 more infections when comparing the maximum number of infections at 1 time point.
